{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- LIBRER√çAS ADAPTADAS PARA RANDOM FOREST Y PERSISTENCIA ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# --- CONFIGURACI√ìN DEL MODELO ---\n",
        "prediction_hour = 1 # Predicci√≥n a 1 hora (H+1)\n",
        "\n",
        "# MODO EXPERIMENTAL: Desactivar lags para probar modelo sin persistencia\n",
        "USE_LAGS = True  # ‚Üê Cambiar a True para activar lags\n",
        "\n",
        "# Caracter√≠sticas que queremos \"desfasar\" (Lags)\n",
        "lag_features = ['ts', 'hr', 'p0']\n",
        "lag_steps = [1, 2, 3] # Desfases de 1, 2 y 3 horas\n",
        "\n",
        "# --- CARGA Y PREPARACI√ìN DEL DATASET √öNICO ---\n",
        "\n",
        "file_path = \"datos_modificados1.csv\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"No se encuentra: {file_path}\")\n",
        "\n",
        "df_raw = pd.read_csv(\"datos_modificados1.csv\")\n",
        "print(df_raw.shape)\n",
        "print(df_raw.columns)\n",
        "\n",
        "print(\"VERIFICACI√ìN DEL DATASET\")\n",
        "\n",
        "# 1. Mostrar primeras filas\n",
        "print(\"Primeras 5 filas del dataset:\")\n",
        "print(df_raw.head(), \"\\n\")\n",
        "\n",
        "# 2. Tipos de datos\n",
        "print(\"Tipos de datos:\")\n",
        "print(df_raw.dtypes, \"\\n\")\n",
        "\n",
        "# 3. Conteo de nulos por columna\n",
        "print(\"Valores nulos por columna:\")\n",
        "print(df_raw.isnull().sum(), \"\\n\")\n",
        "\n",
        "# 4. Filas completamente duplicadas\n",
        "print(f\"Filas duplicadas: {df_raw.duplicated().sum()}\\n\")\n",
        "\n",
        "# 5. Rango y ejemplo de la columna 'momento'\n",
        "if 'momento' in df_raw.columns:\n",
        "    print(\"Columna 'momento' detectada:\")\n",
        "    print(\" - Primer valor:\", df_raw['momento'].iloc[0])\n",
        "    print(\" - √öltimo valor:\", df_raw['momento'].iloc[-1])\n",
        "else:\n",
        "    print(\"ERROR: No existe la columna 'momento' en el dataset\\n\")\n",
        "\n",
        "# 6. Revisar si columnas clave existen\n",
        "columnas_esperadas = ['momento', 'ts', 'hr', 'radiacionGlobalInst', 'ffInst', 'rrInst', 'p0']\n",
        "print(\"Verificando columnas necesarias...\")\n",
        "for col in columnas_esperadas:\n",
        "    if col not in df_raw.columns:\n",
        "        print(f\"Falta columna requerida: {col}\")\n",
        "    else:\n",
        "        print(f\"{col} OK\")\n",
        "print(\"\")\n",
        "\n",
        "# 7. Estad√≠sticas b√°sicas\n",
        "print(\"Estad√≠sticas num√©ricas:\")\n",
        "print(df_raw.describe(), \"\\n\")\n",
        "\n",
        "# 8. Valores fuera de rango sospechosos\n",
        "if 'ts' in df_raw.columns:\n",
        "    ts_min, ts_max = df_raw['ts'].min(), df_raw['ts'].max()\n",
        "    print(f\"Temperatura: min={ts_min}¬∞C | max={ts_max}¬∞C\")\n",
        "    if ts_min < -20 or ts_max > 50:\n",
        "        print(\"Valores at√≠picos detectados en temperatura\\n\")\n",
        "\n",
        "if 'hr' in df_raw.columns:\n",
        "    hr_min, hr_max = df_raw['hr'].min(), df_raw['hr'].max()\n",
        "    print(f\"Humedad relativa: min={hr_min}% | max={hr_max}%\")\n",
        "    if hr_min < 0 or hr_max > 100:\n",
        "        print(\"Humedad fuera de rango (0-100%)\\n\")\n",
        "\n",
        "print(\"\\n======================\")\n",
        "print(\"FIN DE VERIFICACI√ìN DEL DATASET\")\n",
        "print(\"======================\\n\")\n",
        "\n",
        "# Convertir la columna de tiempo a formato datetime y establecerla como √≠ndice\n",
        "df_raw['momento'] = pd.to_datetime(df_raw['momento'])\n",
        "df_raw = df_raw.set_index('momento').sort_index()\n",
        "df_raw = df_raw.dropna()\n",
        "\n",
        "print(\"--- Remuestreando los datos a frecuencia Horaria (h) ---\")\n",
        "\n",
        "# Definir c√≥mo se agregan las columnas en el remuestreo horario\n",
        "resample_rules = {\n",
        "    'ts': 'mean', # Temperatura (Media horaria)\n",
        "    'hr': 'mean', # Humedad (Media horaria)\n",
        "    'radiacionGlobalInst': 'mean', # Radiaci√≥n (Media horaria)\n",
        "    'ffInst': 'mean', # Velocidad del Viento (Media horaria)\n",
        "    'rrInst': 'sum', # Lluvia (Suma horaria)\n",
        "    'p0': 'mean'\n",
        "}\n",
        "\n",
        "# Aplicar remuestreo (corregido 'h' min√∫scula)\n",
        "df = df_raw.resample('h').agg(resample_rules)\n",
        "\n",
        "# --- INGENIER√çA DE CARACTER√çSTICAS TEMPORALES (USANDO 'momento') ---\n",
        "print(\"--- Extrayendo caracter√≠sticas temporales (Hora y D√≠a del A√±o) ---\")\n",
        "df['hour'] = df.index.hour\n",
        "df['dayofyear'] = df.index.dayofyear\n",
        "\n",
        "# --- DEFINICI√ìN DE CARACTER√çSTICAS (X) Y OBJETIVO (Y) ---\n",
        "target = 'ts'\n",
        "\n",
        "# Caracter√≠sticas iniciales\n",
        "features = ['hr', 'p0', 'hour', 'dayofyear']\n",
        "\n",
        "# Crear las caracter√≠sticas desfasadas (lags) - SOLO SI EST√Å ACTIVADO\n",
        "if USE_LAGS:\n",
        "    print(\"Modo: CON Lags (ts_lag_1h, ts_lag_2h, ts_lag_3h...)\")\n",
        "    for feature in lag_features:\n",
        "        for h in lag_steps:\n",
        "            new_col_name = f'{feature}lag{h}h'\n",
        "            df[new_col_name] = df[feature].shift(h)\n",
        "            features.append(new_col_name)\n",
        "else:\n",
        "    print(\"üî∏ Modo: SIN Lags (solo variables f√≠sicas y temporales)\")\n",
        "\n",
        "# Crear la columna objetivo desfasada\n",
        "df[f'ts_future_H{prediction_hour}'] = df[target].shift(-prediction_hour)\n",
        "\n",
        "# Filtrar el DataFrame final y eliminar filas nulas\n",
        "df_model = df[features + [f'ts_future_H{prediction_hour}']].dropna()\n",
        "\n",
        "X = df_model[features]\n",
        "y = df_model[f'ts_future_H{prediction_hour}']\n",
        "\n",
        "print(f\"\\n--- Caracter√≠sticas (X) a usar en el modelo ---\")\n",
        "print(X.columns.tolist())\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# --- DIVISI√ìN DE DATOS: 60% TRAIN, 20% VALIDATION, 20% TEST ---\n",
        "print(\"\\n--- Divisi√≥n de Datos: 60% Train | 20% Validation | 20% Test ---\")\n",
        "\n",
        "total_size = len(df_model)\n",
        "train_size = int(total_size * 0.6)\n",
        "val_size = int(total_size * 0.2)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Divisi√≥n temporal (respetando el orden cronol√≥gico)\n",
        "X_train = X[:train_size]\n",
        "X_val = X[train_size:train_size + val_size]\n",
        "X_test = X[train_size + val_size:]\n",
        "\n",
        "y_train = y[:train_size]\n",
        "y_val = y[train_size:train_size + val_size]\n",
        "y_test = y[train_size + val_size:]\n",
        "\n",
        "print(f\"Train:      {len(X_train):6d} filas ({len(X_train)/total_size*100:.1f}%)\")\n",
        "print(f\"Validation: {len(X_val):6d} filas ({len(X_val)/total_size*100:.1f}%)\")\n",
        "print(f\"Test:       {len(X_test):6d} filas ({len(X_test)/total_size*100:.1f}%)\")\n",
        "print(f\"Total:      {total_size:6d} filas\")\n",
        "\n",
        "# --- MODELO RANDOM FOREST REGRESSOR ---\n",
        "print(\"\\n--- Entrenando Random Forest Regressor ---\")\n",
        "print(\"Hiperpar√°metros: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 100}\")\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# --- FUNCI√ìN AUXILIAR PARA CALCULAR M√âTRICAS ---\n",
        "def calcular_metricas(y_real, y_pred, set_name):\n",
        "    \"\"\"Calcula y muestra MAE, MSE y R¬≤ para un conjunto de datos\"\"\"\n",
        "    mae = mean_absolute_error(y_real, y_pred)\n",
        "    mse = mean_squared_error(y_real, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_real, y_pred)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"M√âTRICAS - {set_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"MAE  (Mean Absolute Error):       {mae:.4f} ¬∞C\")\n",
        "    print(f\"MSE  (Mean Squared Error):        {mse:.4f} ¬∞C¬≤\")\n",
        "    print(f\"RMSE (Root Mean Squared Error):   {rmse:.4f} ¬∞C\")\n",
        "    print(f\"R¬≤   (Coeficiente Determinaci√≥n): {r2:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
        "\n",
        "# --- EVALUACI√ìN EN CONJUNTO DE ENTRENAMIENTO ---\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "metricas_train = calcular_metricas(y_train, y_train_pred, \"TRAIN SET\")\n",
        "\n",
        "# --- EVALUACI√ìN EN CONJUNTO DE VALIDACI√ìN ---\n",
        "y_val_pred = rf_model.predict(X_val)\n",
        "metricas_val = calcular_metricas(y_val, y_val_pred, \"VALIDATION SET\")\n",
        "\n",
        "# --- EVALUACI√ìN EN CONJUNTO DE PRUEBA ---\n",
        "y_test_pred = rf_model.predict(X_test)\n",
        "metricas_test = calcular_metricas(y_test, y_test_pred, \"TEST SET\")\n",
        "\n",
        "# --- DETECCI√ìN DE OVERFITTING ---\n",
        "print(\"\\n--- üîç An√°lisis de Overfitting ---\")\n",
        "diff_train_val_r2 = metricas_train['R2'] - metricas_val['R2']\n",
        "diff_train_val_mae = metricas_val['MAE'] - metricas_train['MAE']\n",
        "\n",
        "print(f\"Diferencia R¬≤ (Train - Val):  {diff_train_val_r2:.4f}\")\n",
        "print(f\"Diferencia MAE (Val - Train): {diff_train_val_mae:.4f} ¬∞C\")\n",
        "\n",
        "if diff_train_val_r2 > 0.05:\n",
        "    print(\"ADVERTENCIA: Posible overfitting detectado (R¬≤ train >> R¬≤ val)\")\n",
        "elif diff_train_val_mae > 0.2:\n",
        "    print(\"ADVERTENCIA: Posible overfitting detectado (MAE val >> MAE train)\")\n",
        "else:\n",
        "    print(\"No se detecta overfitting significativo\")\n",
        "\n",
        "# --- PERSISTENCIA DEL MODELO ---\n",
        "model_filename = f'random_forest_H{prediction_hour}_hourly_full_features.joblib'\n",
        "joblib.dump(rf_model, model_filename)\n",
        "joblib.dump(X.columns.tolist(), f'features_H{prediction_hour}_hourly_full_features.joblib')\n",
        "\n",
        "print(f\"\\nModelo guardado como: {model_filename}\")\n",
        "print(f\"Lista de features guardada como: features_H{prediction_hour}_hourly_full_features.joblib\")\n",
        "\n",
        "# --- IMPORTANCIA DE LAS CARACTER√çSTICAS ---\n",
        "print(\"\\n--- Importancia de las Caracter√≠sticas (Feature Importance) ---\")\n",
        "feature_importances = pd.Series(rf_model.feature_importances_, index=features)\n",
        "feature_importances_sorted = feature_importances.sort_values(ascending=False)\n",
        "print(feature_importances_sorted)\n",
        "\n",
        "# --- VALIDACI√ìN CRUZADA TEMPORAL (SOLO EN TRAIN) ---\n",
        "print(\"\\n--- Validaci√≥n Cruzada Temporal (Time Series CV sobre Train Set) ---\")\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "cv_mae_scores = []\n",
        "cv_mse_scores = []\n",
        "cv_r2_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
        "    X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    rf_temp = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf_temp.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "    y_fold_pred = rf_temp.predict(X_fold_val)\n",
        "    fold_mae = mean_absolute_error(y_fold_val, y_fold_pred)\n",
        "    fold_mse = mean_squared_error(y_fold_val, y_fold_pred)\n",
        "    fold_rmse = np.sqrt(fold_mse)\n",
        "    fold_r2 = r2_score(y_fold_val, y_fold_pred)\n",
        "\n",
        "    cv_mae_scores.append(fold_mae)\n",
        "    cv_mse_scores.append(fold_mse)\n",
        "    cv_r2_scores.append(fold_r2)\n",
        "\n",
        "    print(f\"Fold {fold}: MAE = {fold_mae:.4f}¬∞C | MSE = {fold_mse:.4f} | R¬≤ = {fold_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nPromedio CV: MAE = {np.mean(cv_mae_scores):.4f}¬∞C ¬± {np.std(cv_mae_scores):.4f}\")\n",
        "print(f\"Promedio CV: MSE = {np.mean(cv_mse_scores):.4f} ¬± {np.std(cv_mse_scores):.4f}\")\n",
        "print(f\"Promedio CV: R¬≤  = {np.mean(cv_r2_scores):.4f} ¬± {np.std(cv_r2_scores):.4f}\")\n",
        "\n",
        "# --- VALIDACI√ìN POR ESTACI√ìN DEL A√ëO (EN TEST SET) ---\n",
        "print(\"\\n--- Validaci√≥n por Estaciones del A√±o (Test Set) ---\")\n",
        "\n",
        "def get_season(month):\n",
        "    if month in [12, 1, 2]:\n",
        "        return 'Invierno'\n",
        "    elif month in [3, 4, 5]:\n",
        "        return 'Primavera'\n",
        "    elif month in [6, 7, 8]:\n",
        "        return 'Verano'\n",
        "    else:\n",
        "        return 'Oto√±o'\n",
        "\n",
        "y_test_with_season = pd.DataFrame({\n",
        "    'real': y_test.values,\n",
        "    'pred': y_test_pred,\n",
        "    'season': [get_season(idx.month) for idx in y_test.index]\n",
        "})\n",
        "\n",
        "for season in ['Invierno', 'Primavera', 'Verano', 'Oto√±o']:\n",
        "    mask = y_test_with_season['season'] == season\n",
        "    if mask.sum() > 0:\n",
        "        season_mae = mean_absolute_error(\n",
        "            y_test_with_season.loc[mask, 'real'],\n",
        "            y_test_with_season.loc[mask, 'pred']\n",
        "        )\n",
        "        season_mse = mean_squared_error(\n",
        "            y_test_with_season.loc[mask, 'real'],\n",
        "            y_test_with_season.loc[mask, 'pred']\n",
        "        )\n",
        "        season_r2 = r2_score(\n",
        "            y_test_with_season.loc[mask, 'real'],\n",
        "            y_test_with_season.loc[mask, 'pred']\n",
        "        )\n",
        "        print(f\"{season:12s}: MAE = {season_mae:.4f}¬∞C | MSE = {season_mse:.4f} | R¬≤ = {season_r2:.4f} ({mask.sum()} muestras)\")\n",
        "\n",
        "# --- DETECCI√ìN DE VALORES EXTREMOS ---\n",
        "print(\"\\n--- Detecci√≥n de Predicciones en Condiciones Extremas (Test Set) ---\")\n",
        "\n",
        "temp_p10 = y_train.quantile(0.10)\n",
        "temp_p90 = y_train.quantile(0.90)\n",
        "\n",
        "extreme_cold_mask = y_test < temp_p10\n",
        "extreme_hot_mask = y_test > temp_p90\n",
        "\n",
        "if extreme_cold_mask.sum() > 0:\n",
        "    cold_mae = mean_absolute_error(y_test[extreme_cold_mask], y_test_pred[extreme_cold_mask])\n",
        "    cold_mse = mean_squared_error(y_test[extreme_cold_mask], y_test_pred[extreme_cold_mask])\n",
        "    cold_r2 = r2_score(y_test[extreme_cold_mask], y_test_pred[extreme_cold_mask])\n",
        "    print(f\"‚ùÑ  Fr√≠o extremo (<{temp_p10:.1f}¬∞C): MAE = {cold_mae:.4f}¬∞C | MSE = {cold_mse:.4f} | R¬≤ = {cold_r2:.4f} ({extreme_cold_mask.sum()} casos)\")\n",
        "\n",
        "if extreme_hot_mask.sum() > 0:\n",
        "    hot_mae = mean_absolute_error(y_test[extreme_hot_mask], y_test_pred[extreme_hot_mask])\n",
        "    hot_mse = mean_squared_error(y_test[extreme_hot_mask], y_test_pred[extreme_hot_mask])\n",
        "    hot_r2 = r2_score(y_test[extreme_hot_mask], y_test_pred[extreme_hot_mask])\n",
        "    print(f\"Calor extremo (>{temp_p90:.1f}¬∞C): MAE = {hot_mae:.4f}¬∞C | MSE = {hot_mse:.4f} | R¬≤ = {hot_r2:.4f} ({extreme_hot_mask.sum()} casos)\")\n",
        "\n",
        "# --- AN√ÅLISIS DE ERRORES POR HORA ---\n",
        "print(\"\\n--- An√°lisis de Sesgo Temporal en Errores (Test Set) ---\")\n",
        "\n",
        "errors = y_test - y_test_pred\n",
        "errors_by_hour = pd.DataFrame({\n",
        "    'error': errors.values,\n",
        "    'hour': [idx.hour for idx in y_test.index]\n",
        "}).groupby('hour')['error'].agg(['mean', 'std'])\n",
        "\n",
        "print(\"\\nError promedio por hora del d√≠a:\")\n",
        "print(errors_by_hour.round(4))\n",
        "\n",
        "problematic_hours = errors_by_hour[abs(errors_by_hour['mean']) > 0.5]\n",
        "if not problematic_hours.empty:\n",
        "    print(f\"\\nHoras con sesgo >0.5¬∞C: {problematic_hours.index.tolist()}\")\n",
        "else:\n",
        "    print(\"\\nNo se detectaron horas con sesgo significativo\")\n",
        "\n",
        "# --- GR√ÅFICOS ---\n",
        "print(\"\\n--- Generando Gr√°ficos ---\")\n",
        "\n",
        "# Gr√°fico 1: Predicci√≥n vs Real (Test Set)\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(y_test.index, y_test.values, label='Temperatura Real', alpha=0.7, linewidth=1.5)\n",
        "plt.plot(y_test.index, y_test_pred, label=f'Predicci√≥n RF (H+{prediction_hour})', alpha=0.7, linewidth=1.5)\n",
        "plt.title(f'Predicci√≥n vs Real - Test Set (MAE: {metricas_test[\"MAE\"]:.4f}¬∞C, R¬≤: {metricas_test[\"R2\"]:.4f})')\n",
        "plt.xlabel('Momento')\n",
        "plt.ylabel('Temperatura (¬∞C)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'prediccion_test_H{prediction_hour}.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Gr√°fico 2: Importancia de Caracter√≠sticas\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(feature_importances_sorted.index, feature_importances_sorted.values, color='teal')\n",
        "plt.title('Importancia de las Caracter√≠sticas en Random Forest')\n",
        "plt.xlabel('Importancia')\n",
        "plt.ylabel('Caracter√≠stica')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'feature_importance_H{prediction_hour}.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Gr√°fico 3: Scatter Plot (Test Set)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.5, color='darkred', s=10)\n",
        "max_val = max(y_test.max(), y_test_pred.max())\n",
        "min_val = min(y_test.min(), y_test_pred.min())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Predicci√≥n Perfecta')\n",
        "plt.title(f'Scatter Plot: Real vs Predicci√≥n (Test Set)\\nMAE: {metricas_test[\"MAE\"]:.4f}¬∞C | R¬≤: {metricas_test[\"R2\"]:.4f}')\n",
        "plt.xlabel('Temperatura Real (¬∞C)')\n",
        "plt.ylabel('Temperatura Predicha (¬∞C)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'scatter_test_H{prediction_hour}.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# Gr√°fico 4: Comparaci√≥n de M√©tricas (Train/Val/Test)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "sets = ['Train', 'Validation', 'Test']\n",
        "mae_values = [metricas_train['MAE'], metricas_val['MAE'], metricas_test['MAE']]\n",
        "mse_values = [metricas_train['MSE'], metricas_val['MSE'], metricas_test['MSE']]\n",
        "r2_values = [metricas_train['R2'], metricas_val['R2'], metricas_test['R2']]\n",
        "\n",
        "axes[0].bar(sets, mae_values, color=['blue', 'orange', 'green'])\n",
        "axes[0].set_title('MAE por Conjunto')\n",
        "axes[0].set_ylabel('MAE (¬∞C)')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].bar(sets, mse_values, color=['blue', 'orange', 'green'])\n",
        "axes[1].set_title('MSE por Conjunto')\n",
        "axes[1].set_ylabel('MSE (¬∞C¬≤)')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].bar(sets, r2_values, color=['blue', 'orange', 'green'])\n",
        "axes[2].set_title('R¬≤ por Conjunto')\n",
        "axes[2].set_ylabel('R¬≤')\n",
        "axes[2].set_ylim([0.9, 1.0])\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'metricas_comparacion_H{prediction_hour}.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# =======================================================\n",
        "# 4. Generaci√≥n de Artefactos (Para CML)\n",
        "# =======================================================\n",
        "\n",
        "# 4.1. Guardar el Modelo Entrenado (Formato H5 para Keras/TensorFlow)\n",
        "model_filename = 'lstm_model.h5'\n",
        "# Se asume que tu modelo entrenado se llama 'lstm_model'\n",
        "lstm_model.save(model_filename)\n",
        "print(f\"Modelo LSTM guardado como {model_filename}.\")\n",
        "\n",
        "# 4.2. Generar el Gr√°fico de Predicci√≥n √öNICO (plot_lstm.png)\n",
        "# Aseg√∫rate de que las variables de tu entrenamiento LSTM sean correctas.\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Gr√°fico de Predicciones LSTM vs. Valores Reales\n",
        "plt.scatter(y_test, y_pred, alpha=0.6, color='forestgreen')\n",
        "# L√≠nea perfecta y=x\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
        "plt.title('LSTM: Predicci√≥n vs. Temperatura Real')\n",
        "plt.xlabel('Temperatura M√°xima Real')\n",
        "plt.ylabel('Temperatura M√°xima Predicha')\n",
        "plt.grid(True)\n",
        "plot_filename = 'plot_lstm.png' # <-- Nombre √öNICO\n",
        "plt.savefig(plot_filename)\n",
        "print(f\"Gr√°fico de predicci√≥n LSTM guardado como {plot_filename}.\")\n",
        "\n",
        "# 4.3. Guardar las M√©tricas √öNICAS (metrics_lstm.txt)\n",
        "metrics_filename = 'metrics_lstm.txt' # <-- Nombre √öNICO\n",
        "with open(metrics_filename, 'w') as f:\n",
        "    f.write(\"LSTM Regressor - Predicci√≥n de Temperatura M√°xima\\n\")\n",
        "    f.write(\"-\" * 50 + \"\\n\")\n",
        "    f.write(f\"MSE (Error Cuadr√°tico Medio): {mse:.2f}\\n\")\n",
        "    f.write(f\"R2 Score (Coeficiente de Determinaci√≥n): {r2:.4f}\\n\")\n",
        "print(f\"M√©tricas guardadas en {metrics_filename}.\")\n",
        "\n",
        "# =======================================================\n",
        "# Fin del Script para CML\n",
        "# =======================================================\n",
        "\n",
        "\n",
        "print(\"Gr√°ficos guardados exitosamente\")\n",
        "print(\"\\nArchivos generados:\")\n",
        "print(f\"  - {model_filename}\")\n",
        "print(f\"  - features_H{prediction_hour}_hourly_full_features.joblib\")\n",
        "print(f\"  - prediccion_test_H{prediction_hour}.png\")\n",
        "print(f\"  - feature_importance_H{prediction_hour}.png\")\n",
        "print(f\"  - scatter_test_H{prediction_hour}.png\")\n",
        "print(f\"  - metricas_comparacion_H{prediction_hour}.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKWkERgHhd1G",
        "outputId": "e747c95f-f7ea-4099-e228-d029a6a2e5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(16774505, 12)\n",
            "Index(['momento', 'rrInst', 'hr', 'p0', 'qfe1', 'qff', 'qnh',\n",
            "       'radiacionGlobalInst', 'ts', 'td', 'ddInst', 'ffInst'],\n",
            "      dtype='object')\n",
            "VERIFICACI√ìN DEL DATASET\n",
            "Primeras 5 filas del dataset:\n",
            "               momento  rrInst    hr     p0   qfe1     qff     qnh  \\\n",
            "0  2019-01-01 00:00:00     0.0  28.8  950.4  950.5  1009.1  1011.4   \n",
            "1  2019-01-01 00:01:00     0.0  28.8  950.4  950.5  1009.1  1011.4   \n",
            "2  2019-01-01 00:02:00     0.0  28.8  950.4  950.5  1009.1  1011.4   \n",
            "3  2019-01-01 00:03:00     0.0  28.8  950.4  950.5  1009.1  1011.4   \n",
            "4  2019-01-01 00:04:00     0.0  28.8  950.4  950.5  1009.1  1011.4   \n",
            "\n",
            "   radiacionGlobalInst    ts   td  ddInst  ffInst  \n",
            "0                  0.0  23.6  4.5   211.3     4.7  \n",
            "1                  0.0  23.6  4.5   211.3     4.7  \n",
            "2                  0.0  23.6  4.5   211.3     4.7  \n",
            "3                  0.0  23.6  4.5   211.3     4.7  \n",
            "4                  0.0  23.6  4.5   211.3     4.7   \n",
            "\n",
            "Tipos de datos:\n",
            "momento                 object\n",
            "rrInst                 float64\n",
            "hr                     float64\n",
            "p0                     float64\n",
            "qfe1                   float64\n",
            "qff                    float64\n",
            "qnh                    float64\n",
            "radiacionGlobalInst    float64\n",
            "ts                     float64\n",
            "td                     float64\n",
            "ddInst                 float64\n",
            "ffInst                 float64\n",
            "dtype: object \n",
            "\n",
            "Valores nulos por columna:\n",
            "momento                0\n",
            "rrInst                 0\n",
            "hr                     0\n",
            "p0                     0\n",
            "qfe1                   0\n",
            "qff                    0\n",
            "qnh                    0\n",
            "radiacionGlobalInst    0\n",
            "ts                     0\n",
            "td                     0\n",
            "ddInst                 0\n",
            "ffInst                 0\n",
            "dtype: int64 \n",
            "\n",
            "Filas duplicadas: 387\n",
            "\n",
            "Columna 'momento' detectada:\n",
            " - Primer valor: 2019-01-01 00:00:00\n",
            " - √öltimo valor: 2025-11-01 00:00:00\n",
            "Verificando columnas necesarias...\n",
            "momento OK\n",
            "ts OK\n",
            "hr OK\n",
            "radiacionGlobalInst OK\n",
            "ffInst OK\n",
            "rrInst OK\n",
            "p0 OK\n",
            "\n",
            "Estad√≠sticas num√©ricas:\n",
            "             rrInst            hr            p0          qfe1           qff  \\\n",
            "count  1.677450e+07  1.677450e+07  1.677450e+07  1.677450e+07  1.677450e+07   \n",
            "mean   4.145577e-05  6.173711e+01  9.555893e+02  9.557502e+02  1.017092e+03   \n",
            "std    2.235783e-03  1.754522e+01  2.590081e+00  2.602601e+00  3.893734e+00   \n",
            "min    0.000000e+00  6.300000e+00  5.059970e+02  5.060900e+02  5.383000e+02   \n",
            "25%    0.000000e+00  6.400000e+01  9.557440e+02  9.559000e+02  1.017300e+03   \n",
            "50%    0.000000e+00  6.870000e+01  9.565910e+02  9.567620e+02  1.018720e+03   \n",
            "75%    0.000000e+00  6.870000e+01  9.565910e+02  9.567620e+02  1.018720e+03   \n",
            "max    9.000000e-01  1.000000e+02  9.707700e+02  9.710440e+02  1.036770e+03   \n",
            "\n",
            "                qnh  radiacionGlobalInst            ts            td  \\\n",
            "count  1.677450e+07         1.677450e+07  1.677450e+07  1.677450e+07   \n",
            "mean   1.017527e+03         4.548016e+01  1.973062e+01  5.781534e+00   \n",
            "std    2.959734e+00         1.679374e+02  5.692963e+00  2.200617e+00   \n",
            "min    5.429000e+02         0.000000e+00 -2.500000e+00 -1.480000e+01   \n",
            "25%    1.017660e+03         0.000000e+00  1.370000e+01  4.500000e+00   \n",
            "50%    1.018750e+03         0.000000e+00  2.360000e+01  4.500000e+00   \n",
            "75%    1.018750e+03         0.000000e+00  2.360000e+01  8.000000e+00   \n",
            "max    1.033770e+03         1.407300e+03  3.830000e+01  1.820000e+01   \n",
            "\n",
            "             ddInst        ffInst  \n",
            "count  1.677450e+07  1.677450e+07  \n",
            "mean   1.975433e+02  4.053375e+00  \n",
            "std    5.633611e+01  1.529742e+00  \n",
            "min    0.000000e+00  0.000000e+00  \n",
            "25%    2.113000e+02  4.700000e+00  \n",
            "50%    2.113000e+02  4.700000e+00  \n",
            "75%    2.113000e+02  4.700000e+00  \n",
            "max    3.600000e+02  2.180000e+01   \n",
            "\n",
            "Temperatura: min=-2.5¬∞C | max=38.3¬∞C\n",
            "Humedad relativa: min=6.3% | max=100.0%\n",
            "\n",
            "======================\n",
            "FIN DE VERIFICACI√ìN DEL DATASET\n",
            "======================\n",
            "\n",
            "--- Remuestreando los datos a frecuencia Horaria (h) ---\n",
            "--- Extrayendo caracter√≠sticas temporales (Hora y D√≠a del A√±o) ---\n",
            "Modo: CON Lags (ts_lag_1h, ts_lag_2h, ts_lag_3h...)\n",
            "\n",
            "--- Caracter√≠sticas (X) a usar en el modelo ---\n",
            "['hr', 'p0', 'hour', 'dayofyear', 'tslag1h', 'tslag2h', 'tslag3h', 'hrlag1h', 'hrlag2h', 'hrlag3h', 'p0lag1h', 'p0lag2h', 'p0lag3h']\n",
            "------------------------------------------------------------\n",
            "\n",
            "--- Divisi√≥n de Datos: 60% Train | 20% Validation | 20% Test ---\n",
            "Train:       35899 filas (60.0%)\n",
            "Validation:  11966 filas (20.0%)\n",
            "Test:        11968 filas (20.0%)\n",
            "Total:       59833 filas\n",
            "\n",
            "--- Entrenando Random Forest Regressor ---\n",
            "Hiperpar√°metros: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
            "\n",
            "============================================================\n",
            "M√âTRICAS - TRAIN SET\n",
            "============================================================\n",
            "MAE  (Mean Absolute Error):       0.0850 ¬∞C\n",
            "MSE  (Mean Squared Error):        0.0150 ¬∞C¬≤\n",
            "RMSE (Root Mean Squared Error):   0.1225 ¬∞C\n",
            "R¬≤   (Coeficiente Determinaci√≥n): 0.9936\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "M√âTRICAS - VALIDATION SET\n",
            "============================================================\n",
            "MAE  (Mean Absolute Error):       0.2467 ¬∞C\n",
            "MSE  (Mean Squared Error):        0.1275 ¬∞C¬≤\n",
            "RMSE (Root Mean Squared Error):   0.3571 ¬∞C\n",
            "R¬≤   (Coeficiente Determinaci√≥n): 0.9553\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "M√âTRICAS - TEST SET\n",
            "============================================================\n",
            "MAE  (Mean Absolute Error):       0.3408 ¬∞C\n",
            "MSE  (Mean Squared Error):        0.2119 ¬∞C¬≤\n",
            "RMSE (Root Mean Squared Error):   0.4604 ¬∞C\n",
            "R¬≤   (Coeficiente Determinaci√≥n): 0.9380\n",
            "============================================================\n",
            "\n",
            "--- üîç An√°lisis de Overfitting ---\n",
            "Diferencia R¬≤ (Train - Val):  0.0382\n",
            "Diferencia MAE (Val - Train): 0.1616 ¬∞C\n",
            "No se detecta overfitting significativo\n",
            "\n",
            "Modelo guardado como: random_forest_H1_hourly_full_features.joblib\n",
            "Lista de features guardada como: features_H1_hourly_full_features.joblib\n",
            "\n",
            "--- Importancia de las Caracter√≠sticas (Feature Importance) ---\n",
            "tslag1h      0.850195\n",
            "hour         0.097693\n",
            "tslag3h      0.026731\n",
            "hr           0.009526\n",
            "dayofyear    0.005142\n",
            "hrlag1h      0.002162\n",
            "hrlag3h      0.002090\n",
            "hrlag2h      0.002049\n",
            "tslag2h      0.001634\n",
            "p0           0.001029\n",
            "p0lag3h      0.000635\n",
            "p0lag1h      0.000585\n",
            "p0lag2h      0.000528\n",
            "dtype: float64\n",
            "\n",
            "--- Validaci√≥n Cruzada Temporal (Time Series CV sobre Train Set) ---\n",
            "Fold 1: MAE = 0.1933¬∞C | MSE = 0.0831 | R¬≤ = 0.9623\n",
            "Fold 2: MAE = 0.1564¬∞C | MSE = 0.0469 | R¬≤ = 0.9784\n",
            "Fold 3: MAE = 0.1555¬∞C | MSE = 0.0463 | R¬≤ = 0.9763\n",
            "Fold 4: MAE = 0.1288¬∞C | MSE = 0.0309 | R¬≤ = 0.9836\n",
            "Fold 5: MAE = 0.1374¬∞C | MSE = 0.0359 | R¬≤ = 0.9859\n",
            "\n",
            "Promedio CV: MAE = 0.1543¬∞C ¬± 0.0222\n",
            "Promedio CV: MSE = 0.0486 ¬± 0.0183\n",
            "Promedio CV: R¬≤  = 0.9773 ¬± 0.0082\n",
            "\n",
            "--- Validaci√≥n por Estaciones del A√±o (Test Set) ---\n",
            "Invierno    : MAE = 0.2977¬∞C | MSE = 0.1602 | R¬≤ = 0.9367 (2160 muestras)\n",
            "Primavera   : MAE = 0.3135¬∞C | MSE = 0.1732 | R¬≤ = 0.9280 (2208 muestras)\n",
            "Verano      : MAE = 0.4069¬∞C | MSE = 0.3047 | R¬≤ = 0.8154 (3952 muestras)\n",
            "Oto√±o       : MAE = 0.3113¬∞C | MSE = 0.1655 | R¬≤ = 0.9318 (3648 muestras)\n",
            "\n",
            "--- Detecci√≥n de Predicciones en Condiciones Extremas (Test Set) ---\n",
            "‚ùÑ  Fr√≠o extremo (<18.1¬∞C): MAE = 0.3550¬∞C | MSE = 0.2487 | R¬≤ = 0.5098 (4712 casos)\n",
            "Calor extremo (>22.3¬∞C): MAE = 0.1616¬∞C | MSE = 0.0432 | R¬≤ = 0.7201 (653 casos)\n",
            "\n",
            "--- An√°lisis de Sesgo Temporal en Errores (Test Set) ---\n",
            "\n",
            "Error promedio por hora del d√≠a:\n",
            "        mean     std\n",
            "hour                \n",
            "0    -0.2827  0.2536\n",
            "1    -0.2072  0.2274\n",
            "2    -0.1897  0.2276\n",
            "3    -0.1868  0.2330\n",
            "4    -0.1654  0.2456\n",
            "5    -0.1449  0.2571\n",
            "6    -0.1475  0.2656\n",
            "7    -0.1300  0.2695\n",
            "8    -0.1203  0.2828\n",
            "9    -0.0244  0.3317\n",
            "10    0.1438  0.6049\n",
            "11    0.1261  0.7221\n",
            "12    0.1621  0.6968\n",
            "13    0.2574  0.5475\n",
            "14    0.2258  0.4200\n",
            "15    0.1423  0.3584\n",
            "16    0.0618  0.3367\n",
            "17    0.0068  0.3276\n",
            "18   -0.0580  0.3021\n",
            "19   -0.1414  0.2937\n",
            "20   -0.2884  0.3518\n",
            "21   -0.4642  0.4282\n",
            "22   -0.5418  0.3866\n",
            "23   -0.5221  0.4359\n",
            "\n",
            "Horas con sesgo >0.5¬∞C: [22, 23]\n",
            "\n",
            "--- Generando Gr√°ficos ---\n",
            "Gr√°ficos guardados exitosamente\n",
            "\n",
            "Archivos generados:\n",
            "  - random_forest_H1_hourly_full_features.joblib\n",
            "  - features_H1_hourly_full_features.joblib\n",
            "  - prediccion_test_H1.png\n",
            "  - feature_importance_H1.png\n",
            "  - scatter_test_H1.png\n",
            "  - metricas_comparacion_H1.png\n"
          ]
        }
      ]
    }
  ]
}